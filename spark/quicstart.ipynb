{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 使用Spark模型实践LangChain功能"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import logging\n",
    "from spark.LLMService.SparkLLM import SparkLLM\n",
    "\n",
    "# 设置日志级别\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "llm = SparkLLM()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 直接调用"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:spark.LLMService.SparkLLM:讲一个关于中国足球的笑话\n",
      "DEBUG:spark.LLMService.SparkLLM:SparkLLM response: 有一天，中国足球队的教练在训练场上对球员们说：“今天我们要进行一场特殊的训练，那就是闭着眼睛踢球。”\n",
      "\n",
      "球员们都觉得很好奇，于是纷纷闭上眼睛开始尝试。然而，他们发现这并不容易，因为足球场上有很多障碍物，而且他们还要与队友配合。\n",
      "\n",
      "过了一会儿，教练看着球员们摸索着踢球的样子，忍不住笑了出来。他问球员们：“你们觉得这个训练有什么意义吗？”\n",
      "\n",
      "一个球员想了想，回答说：“教练，我觉得这个训练让我们明白了一个道理：要想在足球场上取得成功，光靠眼睛是不够的，我们还需要用心去感受。”\n",
      "\n",
      "教练听了，满意地点了点头：“没错，足球不仅仅是一项运动，更是一种精神。只要我们用心去踢，总有一天会取得好成绩的。”\n"
     ]
    },
    {
     "data": {
      "text/plain": "'有一天，中国足球队的教练在训练场上对球员们说：“今天我们要进行一场特殊的训练，那就是闭着眼睛踢球。”\\n\\n球员们都觉得很好奇，于是纷纷闭上眼睛开始尝试。然而，他们发现这并不容易，因为足球场上有很多障碍物，而且他们还要与队友配合。\\n\\n过了一会儿，教练看着球员们摸索着踢球的样子，忍不住笑了出来。他问球员们：“你们觉得这个训练有什么意义吗？”\\n\\n一个球员想了想，回答说：“教练，我觉得这个训练让我们明白了一个道理：要想在足球场上取得成功，光靠眼睛是不够的，我们还需要用心去感受。”\\n\\n教练听了，满意地点了点头：“没错，足球不仅仅是一项运动，更是一种精神。只要我们用心去踢，总有一天会取得好成绩的。”'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"讲一个关于中国足球的笑话\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用提示词模板"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:spark.LLMService.SparkLLM:给我讲一个关于中国足球的笑话\n",
      "DEBUG:spark.LLMService.SparkLLM:SparkLLM response: 有一天，一位外国朋友来到中国，他非常好奇地问一位中国人：“你们中国足球的水平怎么样？”\n",
      "\n",
      "中国人微笑着回答：“我们的足球水平在世界上排名不是很高，但是我们有一项世界领先的技术。”\n",
      "\n",
      "外国人很好奇地问：“哦？那是什么技术？”\n",
      "\n",
      "中国人自豪地说：“我们拥有世界上最先进的足球裁判技术！”\n"
     ]
    },
    {
     "data": {
      "text/plain": "'有一天，一位外国朋友来到中国，他非常好奇地问一位中国人：“你们中国足球的水平怎么样？”\\n\\n中国人微笑着回答：“我们的足球水平在世界上排名不是很高，但是我们有一项世界领先的技术。”\\n\\n外国人很好奇地问：“哦？那是什么技术？”\\n\\n中国人自豪地说：“我们拥有世界上最先进的足球裁判技术！”'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"joke\", \"name\"],\n",
    "    template=\"给我讲一个关于{joke}的笑话\",\n",
    "    validate_template=True\n",
    ")\n",
    "prompt = prompt_template.format(joke='中国足球')\n",
    "llm.invoke(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "template = \"给我讲一个关于{joke}的笑话\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt = prompt_template.format(joke='中国足球')\n",
    "# llm.invoke(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 序列化提示词模板"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['joke'] template='给我讲一个关于{joke}的笑话'\n",
      "input_variables=['joke'] template='给我讲一个关于{joke}的笑话'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "# 序列化提示词模板\n",
    "prompt_template.save(\"joke_prompt.json\")\n",
    "prompt_template.save(\"joke_prompt.yaml\")\n",
    "# 反序列化提示词模板\n",
    "loaded_prompt = load_prompt(\"joke_prompt.json\")\n",
    "print(loaded_prompt)\n",
    "loaded_prompt = load_prompt(\"joke_prompt.yaml\")\n",
    "print(loaded_prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 具有少量示例的提示词模板"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对于每个输入，给出其反义词 \n",
      "单词: 高兴\n",
      "反义词: 难过\n",
      "\n",
      " \n",
      "单词: 高\n",
      "反义词: 矮\n",
      "\n",
      " 单词: 大\n",
      "反义词:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"word\": \"高兴\", \"antonym\": \"难过\"},\n",
    "    {\"word\": \"高\", \"antonym\": \"矮\"},\n",
    "]\n",
    "example_formatter_template = \"\"\"\n",
    "单词: {word}\n",
    "反义词: {antonym}\\n\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"对于每个输入，给出其反义词\",\n",
    "    suffix=\"单词: {input}\\n反义词:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\" \",\n",
    ")\n",
    "print(few_shot_prompt.format(input='大'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 输出解析器"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PydanticOutputParser' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 19\u001B[0m\n\u001B[0;32m     15\u001B[0m new_parser \u001B[38;5;241m=\u001B[39m OutputFixingParser\u001B[38;5;241m.\u001B[39mfrom_llm(parser\u001B[38;5;241m=\u001B[39mparser, llm\u001B[38;5;241m=\u001B[39mllm)\n\u001B[0;32m     17\u001B[0m misformatted \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTom Hanks\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfilm_names\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: [\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mForrest Gump\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m]}\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 19\u001B[0m \u001B[43mnew_parser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmisformatted\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'PydanticOutputParser' object is not callable"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "new_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
    "\n",
    "misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\"\n",
    "\n",
    "new_parser.parser(misformatted)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "#     input_variables=[\"query\"],\n",
    "#     partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "# )\n",
    "#\n",
    "# # And a query intented to prompt a language model to populate the data structure.\n",
    "# joke_query = \"Tell me a joke.\"\n",
    "# _input = prompt.format_prompt(query=joke_query)\n",
    "# output = llm.invoke(_input.to_string())\n",
    "# parser.parse(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:spark.LLMService.SparkLLM:列出5种比亚迪电车.\n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n",
      "DEBUG:spark.LLMService.SparkLLM:SparkLLM response: 比亚迪唐EV, 比亚迪汉EV, 比亚迪宋Pro EV, 比亚迪秦Pro EV, 比亚迪e2\n"
     ]
    },
    {
     "data": {
      "text/plain": "['比亚迪唐EV', '比亚迪汉EV', '比亚迪宋Pro EV', '比亚迪秦Pro EV', '比亚迪e2']"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"列出5种{car}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "_input = prompt.format(car=\"比亚迪电车\")\n",
    "output = llm.invoke(_input)\n",
    "output_parser.parse(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 调用链"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:spark.LLMService.SparkLLM:给我讲一个关于中国足球的笑话\n",
      "DEBUG:spark.LLMService.SparkLLM:SparkLLM response: 有一天，一位外国朋友来到中国，他非常好奇地问中国朋友：“你们中国人为什么喜欢踢足球呢？”\n",
      "\n",
      "中国朋友回答：“因为我们中国人热爱运动，足球是我们的国球。”\n",
      "\n",
      "外国朋友又问：“那你们的国家队在国际比赛中表现如何呢？”\n",
      "\n",
      "中国朋友笑着说：“我们的国家队在国际比赛中表现得非常出色，总是能够给对手带来惊喜。”\n",
      "\n",
      "外国朋友疑惑地问：“真的吗？那你们的国家队在世界排名是多少呢？”\n",
      "\n",
      "中国朋友想了想，回答：“我们国家队的世界排名总是在变化，有时候我们会排在第一，有时候我们会排在第二，还有时候我们会排在第三。”\n",
      "\n",
      "外国朋友更加疑惑了：“那到底你们国家队的世界排名是多少呢？”\n",
      "\n",
      "中国朋友微笑着说：“其实，我们国家队的世界排名并不重要，重要的是我们永远热爱足球，永远支持我们的国家队。”\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'joke': '中国足球',\n 'text': '有一天，一位外国朋友来到中国，他非常好奇地问中国朋友：“你们中国人为什么喜欢踢足球呢？”\\n\\n中国朋友回答：“因为我们中国人热爱运动，足球是我们的国球。”\\n\\n外国朋友又问：“那你们的国家队在国际比赛中表现如何呢？”\\n\\n中国朋友笑着说：“我们的国家队在国际比赛中表现得非常出色，总是能够给对手带来惊喜。”\\n\\n外国朋友疑惑地问：“真的吗？那你们的国家队在世界排名是多少呢？”\\n\\n中国朋友想了想，回答：“我们国家队的世界排名总是在变化，有时候我们会排在第一，有时候我们会排在第二，还有时候我们会排在第三。”\\n\\n外国朋友更加疑惑了：“那到底你们国家队的世界排名是多少呢？”\\n\\n中国朋友微笑着说：“其实，我们国家队的世界排名并不重要，重要的是我们永远热爱足球，永远支持我们的国家队。”'}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"中国足球\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in d:\\dev\\miniconda3\\envs\\langchain\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\dev\\miniconda3\\envs\\langchain\\lib\\site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in d:\\dev\\miniconda3\\envs\\langchain\\lib\\site-packages (from pydantic) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\dev\\miniconda3\\envs\\langchain\\lib\\site-packages (from pydantic) (4.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydantic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}