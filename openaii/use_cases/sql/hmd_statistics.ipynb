{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1.数据库配置"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "db = SQLDatabase.from_uri(\"postgresql://postgres:3h1admin@192.168.1.135:5432/hmd_test_240129\")\n",
    "\n",
    "context = db.get_context()\n",
    "# print(list(context))\n",
    "# print(context['table_info'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.OpenAI模型对象构建"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='D:\\\\dev\\\\miniconda3\\\\envs\\\\langchain\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='D:\\\\dev\\\\miniconda3\\\\envs\\\\langchain\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='D:\\\\dev\\\\miniconda3\\\\envs\\\\langchain\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='D:\\\\dev\\\\miniconda3\\\\envs\\\\langchain\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='D:\\\\dev\\\\miniconda3\\\\envs\\\\langchain\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='D:\\\\dev\\\\miniconda3\\\\envs\\\\langchain\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.获取与用户问题相关联的表名\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "question = \"2024年2月份总加班工时？\"\n",
    "\n",
    "class Table(BaseModel):\n",
    "    \"\"\"Table in SQL database.\"\"\"\n",
    "    name: str = Field(description=\"数据库表名称\")\n",
    "\n",
    "table_names = \"\\n\".join(db.get_usable_table_names())\n",
    "system = f\"\"\"返回所有与用户问题有关联数据库表名称 \\\n",
    "The tables are:\n",
    "\n",
    "{table_names}\n",
    "\n",
    "Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n",
    "table_chain = create_extraction_chain_pydantic(Table, llm, system_message=system)\n",
    "# table_chain.invoke({\"input\": {question}})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4.获取SQL语句"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def get_tables(categories: List[Table]) -> List[str]:\n",
    "    tables = []\n",
    "    for category in categories:\n",
    "        tables.append(category.name)\n",
    "    return tables\n",
    "\n",
    "table_chain = table_chain | get_tables\n",
    "# table_chain.invoke({\"input\": {question}})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from openaii.use_cases.runnable_tools import StdOutputRunnable\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "table_chain = {\"input\": itemgetter(\"question\")} | table_chain | StdOutputRunnable()\n",
    "query_chain = RunnablePassthrough.assign(table_names_to_use=table_chain) | StdOutputRunnable() | write_query\n",
    "\n",
    "# query_chain.invoke({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.执行SQL语句"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "execute_chain = query_chain | StdOutputRunnable() |execute_query\n",
    "# execute_chain.invoke(\n",
    "#     {\"question\": question}\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6.SQL结果生成自然语言"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"返回所有与用户问题有关联数据库表名称 The tables are:\\n\\nact_app_appdef\\nact_app_databasechangelog\\nact_app_databasechangeloglock\\nact_app_deployment\\nact_app_deployment_resource\\nact_cmmn_casedef\\nact_cmmn_databasechangelog\\nact_cmmn_databasechangeloglock\\nact_cmmn_deployment\\nact_cmmn_deployment_resource\\nact_cmmn_hi_case_inst\\nact_cmmn_hi_mil_inst\\nact_cmmn_hi_plan_item_inst\\nact_cmmn_ru_case_inst\\nact_cmmn_ru_mil_inst\\nact_cmmn_ru_plan_item_inst\\nact_cmmn_ru_sentry_part_inst\\nact_co_content_item\\nact_co_databasechangelog\\nact_co_databasechangeloglock\\nact_de_databasechangelog\\nact_de_databasechangeloglock\\nact_de_model\\nact_de_model_history\\nact_de_model_relation\\nact_dmn_databasechangelog\\nact_dmn_databasechangeloglock\\nact_dmn_decision_table\\nact_dmn_deployment\\nact_dmn_deployment_resource\\nact_dmn_hi_decision_execution\\nact_evt_log\\nact_fo_databasechangelog\\nact_fo_databasechangeloglock\\nact_fo_form_definition\\nact_fo_form_deployment\\nact_fo_form_instance\\nact_fo_form_resource\\nact_ge_bytearray\\nact_ge_property\\nact_hi_actinst\\nact_hi_attachment\\nact_hi_comment\\nact_hi_detail\\nact_hi_entitylink\\nact_hi_identitylink\\nact_hi_procinst\\nact_hi_taskinst\\nact_hi_tsk_log\\nact_hi_varinst\\nact_id_bytearray\\nact_id_group\\nact_id_info\\nact_id_membership\\nact_id_priv\\nact_id_priv_mapping\\nact_id_property\\nact_id_token\\nact_id_user\\nact_procdef_info\\nact_re_deployment\\nact_re_model\\nact_re_procdef\\nact_ru_actinst\\nact_ru_deadletter_job\\nact_ru_entitylink\\nact_ru_event_subscr\\nact_ru_execution\\nact_ru_history_job\\nact_ru_identitylink\\nact_ru_job\\nact_ru_suspended_job\\nact_ru_task\\nact_ru_timer_job\\nact_ru_variable\\nblade_attach\\nblade_client\\nblade_code\\nblade_datasource\\nblade_dept\\nblade_dict\\nblade_dict_biz\\nblade_log_api\\nblade_log_error\\nblade_log_usual\\nblade_menu\\nblade_notice\\nblade_oss\\nblade_param\\nblade_post\\nblade_process_leave\\nblade_region\\nblade_report_file\\nblade_role\\nblade_role_menu\\nblade_role_scope\\nblade_scope_api\\nblade_scope_data\\nblade_scope_data_230525\\nblade_sms\\nblade_tenant\\nblade_top_menu\\nblade_top_menu_setting\\nblade_user\\nblade_user_dept\\nblade_user_oauth\\ndept_head\\nfile_upload_info\\nh_bank_account\\nh_business\\nh_business_correct\\nh_business_correct_self_innovate_product\\nh_business_self_innovate_product\\nh_check\\nh_contract_amount_tax_rate\\nh_contract_file\\nh_contract_month_number\\nh_defined_supplier\\nh_defined_supplier_correct\\nh_dept_leader\\nh_exhibition_expense_dict\\nh_expense_account_cover\\nh_expense_account_cover_detail\\nh_expense_account_travel\\nh_expense_account_travel_details\\nh_home_component\\nh_home_role\\nh_human_care\\nh_human_care_record\\nh_invoice_information\\nh_invoicing_invalid\\nh_invoicing_status\\nh_kpi_detail\\nh_kpi_latitude\\nh_kpi_management\\nh_kpi_my\\nh_kpi_scope\\nh_kpi_target\\nh_kpi_template\\nh_my_project\\nh_my_project_all\\nh_my_project_collaborator\\nh_my_project_file\\nh_my_project_milepost\\nh_my_project_report\\nh_office_payment_plan\\nh_office_purchase\\nh_office_receipt_status\\nh_other_use_money\\nh_payment_plan\\nh_performance_bond\\nh_performance_bond_pay\\nh_performance_bond_receive\\nh_personal_bank\\nh_personal_loan\\nh_personnel_information\\nh_process_note\\nh_project\\nh_project_invalid\\nh_project_royalties_process\\nh_project_scope\\nh_purchase_contract\\nh_purchase_payment_process\\nh_purchase_payment_process_association\\nh_purchase_update\\nh_purchasing_contract_association\\nh_push_info\\nh_push_personnel\\nh_receipt_status\\nh_repayment_schedule\\nh_sales_collection_plan\\nh_sales_collection_process\\nh_sales_contract\\nh_sales_self_innovate_product\\nh_sales_update\\nh_sales_update_detail\\nh_schedule\\nh_schedule_collaborator\\nh_schedule_dynamic\\nh_self_innovate_product\\nh_shy_class\\nh_shy_class_collaborator\\nh_supplier_customer\\nh_user_post_rank\\nh_wage_file\\nh_wage_schedule\\nh_work_time\\nh_work_time_detail\\n\\nRemember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"}, {'role': 'user', 'content': '2024年2月份总加班工时？'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.0, 'tools': [{'type': 'function', 'function': {'name': 'Table', 'description': 'Table in SQL database.', 'parameters': {'type': 'object', 'properties': {'name': {'description': '数据库表名称', 'type': 'string'}}, 'required': ['name']}}}]}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=1089 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000163F621A590>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'CONNECT']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'CONNECT']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'CONNECT']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])\n",
      "DEBUG:httpcore.proxy:start_tls.started ssl_context=<ssl.SSLContext object at 0x00000163F6193240> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.proxy:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000163F621A5C0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 23 Feb 2024 01:20:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-afy5yzv93geh2cq6ef0fp6be'), (b'openai-processing-ms', b'984'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'196'), (b'x-ratelimit-remaining-tokens', b'39039'), (b'x-ratelimit-reset-requests', b'28m6.331s'), (b'x-ratelimit-reset-tokens', b'1.441s'), (b'x-request-id', b'req_1fc23cd7ed191f562ceb8bc38c80e64a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ENXImDccgiyC6gkbdTcFfkQ7f5lB.9j9utIaAMcPN7k-1708651217-1.0-Adq9VyhSloUFi4z6yb5dTwzThPlMwF/N+o034fCcdTV9mnEwIWw29AgUmcha3OZQvJ+L4jXTzgFIEGCJRR+Y+XA=; path=/; expires=Fri, 23-Feb-24 01:50:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=f.HdPtiKUoj8nGP7kZGtCMVpTpGlaJ.bk1wcJ35IlMM-1708651217958-0.0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'859ba5386cb144bf-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a PostgreSQL expert. Given an input question, first create a syntactically correct PostgreSQL query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per PostgreSQL. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use CURRENT_DATE function to get the current date, if the question involves \"today\".\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n\\nCREATE TABLE h_work_time (\\n\\tid BIGINT NOT NULL, \\n\\ttype INTEGER, \\n\\tname VARCHAR(255), \\n\\tstart_time TIMESTAMP(6) WITHOUT TIME ZONE, \\n\\tend_time TIMESTAMP(6) WITHOUT TIME ZONE, \\n\\tduration NUMERIC(12, 2), \\n\\tschedule_id BIGINT, \\n\\tcreate_user BIGINT, \\n\\tcreate_dept BIGINT, \\n\\tcreate_time TIMESTAMP(6) WITHOUT TIME ZONE, \\n\\tupdate_user BIGINT, \\n\\tupdate_time TIMESTAMP(6) WITHOUT TIME ZONE, \\n\\tstatus INTEGER, \\n\\tis_deleted INTEGER, \\n\\tmy_project_id BIGINT, \\n\\tparent_id BIGINT, \\n\\thave_children INTEGER, \\n\\twork_details VARCHAR(255), \\n\\tprocess_id VARCHAR(255), \\n\\tshy_class_id BIGINT, \\n\\twork_type INTEGER DEFAULT 0, \\n\\tCONSTRAINT h_work_time_pkey PRIMARY KEY (id)\\n)\\n\\n/*\\n3 rows from h_work_time table:\\nid\\ttype\\tname\\tstart_time\\tend_time\\tduration\\tschedule_id\\tcreate_user\\tcreate_dept\\tcreate_time\\tupdate_user\\tupdate_time\\tstatus\\tis_deleted\\tmy_project_id\\tparent_id\\thave_children\\twork_details\\tprocess_id\\tshy_class_id\\twork_type\\n1498589871898374146\\t3\\tNone\\t2022-03-01 08:30:00\\tNone\\t1.00\\tNone\\t1422368607676723202\\t11\\t2022-03-01 17:24:02.572000\\t1422368607676723202\\t2022-03-01 17:24:02.572000\\t1\\t0\\t1498589368196018178\\t1498589871831265282\\t0\\tNone\\tNone\\tNone\\t0\\n1498603637629267969\\t3\\tNone\\t2022-03-01 08:30:00\\tNone\\t5.00\\tNone\\t1347360779190947841\\t11\\t2022-03-01 18:18:44.577000\\t1347360779190947841\\t2022-03-01 18:18:44.577000\\t1\\t1\\t1498560647724544002\\t1498603637570547713\\t0\\tNone\\tNone\\tNone\\t0\\n1498590084084019201\\t2\\tNone\\t2022-03-01 09:30:00\\tNone\\t1.50\\tNone\\t1422368607676723202\\t11\\t2022-03-01 17:24:53.160000\\t1422368607676723202\\t2022-03-01 17:24:53.160000\\t1\\t0\\tNone\\t1498590084016910338\\t0\\tNone\\tNone\\tNone\\t0\\n*/\\n\\n\\nCREATE TABLE h_work_time_detail (\\n\\tid BIGINT NOT NULL, \\n\\twork_time_id BIGINT, \\n\\twork_details VARCHAR(255), \\n\\tstart_time TIMESTAMP(6) WITHOUT TIME ZONE, \\n\\tend_time TIMESTAMP(6) WITHOUT TIME ZONE, \\n\\tcreate_user BIGINT, \\n\\tcreate_dept BIGINT, \\n\\tcreate_time TIMESTAMP(6) WITHOUT TIME ZONE, \\n\\tupdate_user BIGINT, \\n\\tupdate_time TIMESTAMP(6) WITHOUT TIME ZONE, \\n\\tstatus INTEGER, \\n\\tis_deleted INTEGER, \\n\\tduration NUMERIC(12, 2), \\n\\tCONSTRAINT h_work_time_detail_pkey PRIMARY KEY (id)\\n)\\n\\n/*\\n3 rows from h_work_time_detail table:\\nid\\twork_time_id\\twork_details\\tstart_time\\tend_time\\tcreate_user\\tcreate_dept\\tcreate_time\\tupdate_user\\tupdate_time\\tstatus\\tis_deleted\\tduration\\n\\n*/\\n\\nQuestion: 2024年2月份总加班工时？\\nSQLQuery: '}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stop': ['\\nSQLResult:'], 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h_work_time', 'h_work_time_detail']\n",
      "{'question': '2024年2月份总加班工时？', 'table_names_to_use': ['h_work_time', 'h_work_time_detail']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 23 Feb 2024 01:20:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-afy5yzv93geh2cq6ef0fp6be'), (b'openai-processing-ms', b'1060'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'195'), (b'x-ratelimit-remaining-tokens', b'38994'), (b'x-ratelimit-reset-requests', b'35m16.884s'), (b'x-ratelimit-reset-tokens', b'1.507s'), (b'x-request-id', b'req_642681d5d3b9d7467fe19a774ca719a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'859ba5418a9944bf-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n\\nQuestion: 2024年2月份总加班工时？\\nSQL Query: SELECT SUM(duration) AS total_overtime_hours\\nFROM h_work_time\\nWHERE EXTRACT(YEAR FROM start_time) = 2024 AND EXTRACT(MONTH FROM start_time) = 2 AND type = 3\\nSQL Result: [(Decimal('4710.00'),)]\\nAnswer: \"}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT SUM(duration) AS total_overtime_hours\n",
      "FROM h_work_time\n",
      "WHERE EXTRACT(YEAR FROM start_time) = 2024 AND EXTRACT(MONTH FROM start_time) = 2 AND type = 3\n",
      "[(Decimal('4710.00'),)]\n",
      "text=\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n\\nQuestion: 2024年2月份总加班工时？\\nSQL Query: SELECT SUM(duration) AS total_overtime_hours\\nFROM h_work_time\\nWHERE EXTRACT(YEAR FROM start_time) = 2024 AND EXTRACT(MONTH FROM start_time) = 2 AND type = 3\\nSQL Result: [(Decimal('4710.00'),)]\\nAnswer: \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Fri, 23 Feb 2024 01:20:21 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'493'), (b'Connection', b'keep-alive'), (b'retry-after', b'20'), (b'retry-after-ms', b'20000'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'194'), (b'x-ratelimit-remaining-tokens', b'39893'), (b'x-ratelimit-reset-requests', b'42m25.622s'), (b'x-ratelimit-reset-tokens', b'160ms'), (b'x-request-id', b'req_e9480b2401f82f0821b3300723b07494'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'859ba555e90444bf-SIN'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"429 Too Many Requests\"\n",
      "DEBUG:openai._base_client:Encountered httpx.HTTPStatusError\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\dev\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\_base_client.py\", line 959, in _request\n",
      "    response.raise_for_status()\n",
      "  File \"D:\\dev\\miniconda3\\envs\\langchain\\lib\\site-packages\\httpx\\_models.py\", line 759, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
      "DEBUG:openai._base_client:Retrying due to status code 429\n",
      "DEBUG:openai._base_client:1 retry left\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 20.000000 seconds\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n\\nQuestion: 2024年2月份总加班工时？\\nSQL Query: SELECT SUM(duration) AS total_overtime_hours\\nFROM h_work_time\\nWHERE EXTRACT(YEAR FROM start_time) = 2024 AND EXTRACT(MONTH FROM start_time) = 2 AND type = 3\\nSQL Result: [(Decimal('4710.00'),)]\\nAnswer: \"}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=1089 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000163F61B3820>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'CONNECT']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'CONNECT']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'CONNECT']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])\n",
      "DEBUG:httpcore.proxy:start_tls.started ssl_context=<ssl.SSLContext object at 0x00000163F6193240> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.proxy:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000163F623F610>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 23 Feb 2024 01:20:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-afy5yzv93geh2cq6ef0fp6be'), (b'openai-processing-ms', b'677'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'193'), (b'x-ratelimit-remaining-tokens', b'39893'), (b'x-ratelimit-reset-requests', b'49m17.066s'), (b'x-ratelimit-reset-tokens', b'160ms'), (b'x-request-id', b'req_85fdd4f3979eff8b018440572813938b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Z51NhMjEJQkrP6UQzcfpbD5UA.neLxLnGgcSS6l9g90-1708651242-1.0-Ae0MKAiVMst/1jtmnoKFRMpLxkrdVkS8SW2u5hHgliuPox2lPAnIAb+q34Xut97TywqNjmjzNrDDQBdBuoaFCTA=; path=/; expires=Fri, 23-Feb-24 01:50:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=8E1AEHxA7BW_S9bSHvj3pTsuBQpVTkiig4vqg6sIKXo-1708651242873-0.0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'859ba5d69e738089-NRT'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "'2024年2月份总加班工时为4710小时。'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "answer = answer_prompt | StdOutputRunnable() | llm | StrOutputParser()\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=query_chain).assign(\n",
    "        result=itemgetter(\"query\") | StdOutputRunnable() | execute_query | StdOutputRunnable()\n",
    "    )\n",
    "    | answer\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}